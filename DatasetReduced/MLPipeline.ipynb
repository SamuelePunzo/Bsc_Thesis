{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from combat.pycombat import pycombat\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../Dataset/Merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('MergedDataset-136411.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\combat\\pycombat.py:159: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.absolute(d_new-d_old)/d_old))  # maximum difference between new and old estimate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the Data\n"
     ]
    }
   ],
   "source": [
    "sampleID = dataset['SampleID']\n",
    "datasetID = dataset['SampleID'].apply(lambda x: x.split('-')[0]).values\n",
    "indicator = dataset['Label']\n",
    "dataset = dataset.drop(columns=['SampleID', 'Label'])\n",
    "\n",
    "dataset = pycombat(dataset.transpose(), datasetID).transpose()\n",
    "\n",
    "dataset.insert(0, 'SampleID', sampleID)\n",
    "dataset.insert(1, 'Label', indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         SampleID      PatientID  Label  \\\n",
      "0                        0-GSM1026056_600009.0001  0-600009.0001      1   \n",
      "1             0-GSM1026057_600009.0001-FollowUp_1  0-600009.0001      1   \n",
      "2                         0-GSM1026058_41461.0001   0-41461.0001      1   \n",
      "3                         0-GSM1026059_41462.0001   0-41462.0001      1   \n",
      "4                        0-GSM1026060_600029.0001  0-600029.0001      1   \n",
      "...                                           ...            ...    ...   \n",
      "1799  5-GSM2347715_NT142_W18D2-Control-FollowUp_1  5-NT142_W18D2      0   \n",
      "1800  5-GSM2347717_NT041_W18D2-Control-FollowUp_2  5-NT041_W18D2      0   \n",
      "1801  5-GSM2347719_NT142_W18D2-Control-FollowUp_2  5-NT142_W18D2      0   \n",
      "1802  5-GSM2347721_NT041_W18D2-Control-FollowUp_3  5-NT041_W18D2      0   \n",
      "1803  5-GSM2347723_NT142_W18D2-Control-FollowUp_3  5-NT142_W18D2      0   \n",
      "\n",
      "        STEEP1   SEC14L1     YIPF5    SLC1A5        C2      NOL6     SPRR3  \\\n",
      "0     5.140886  8.939040  7.488400  7.308738  5.041389  7.277062  4.196267   \n",
      "1     5.329654  8.963625  7.489870  7.253862  5.052384  7.265726  4.194572   \n",
      "2     5.334372  8.988408  7.494769  7.255859  5.088023  7.264864  4.238121   \n",
      "3     5.569576  8.951902  7.528364  7.242488  4.982092  7.261708  4.153170   \n",
      "4     5.400919  8.974480  7.506864  7.262843  5.105506  7.250928  4.162485   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1799  5.609098  8.824586  7.598167  6.961956  4.745473  7.147771  4.175185   \n",
      "1800  5.493972  9.086668  7.444133  7.146979  5.391719  7.108745  4.200994   \n",
      "1801  4.592469  8.675869  7.609213  6.715370  4.550844  7.096102  4.157819   \n",
      "1802  5.992676  9.085231  7.454065  7.371060  5.636887  7.157697  4.151017   \n",
      "1803  5.547987  8.728035  7.581867  6.792434  4.405267  7.090149  4.265779   \n",
      "\n",
      "      ...     PALLD     KRCC1     RAB25  CATSPERB      PAX8     KCNG1  \\\n",
      "0     ...  5.308174  7.072927  4.488145  4.631166  6.337192  5.362835   \n",
      "1     ...  5.289479  7.079105  4.536805  4.606074  6.356049  5.377468   \n",
      "2     ...  5.314215  7.115176  4.518818  4.597691  6.388240  5.391885   \n",
      "3     ...  5.269752  7.316362  4.446099  4.676782  6.334405  5.321966   \n",
      "4     ...  5.243430  7.192371  4.505834  4.569492  6.339356  5.303483   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "1799  ...  5.767658  7.442899  4.478639  5.736174  6.343809  5.550462   \n",
      "1800  ...  5.437960  7.321505  4.442908  4.189680  6.385842  5.210415   \n",
      "1801  ...  5.251095  7.349944  4.397669  5.718701  6.316099  5.223182   \n",
      "1802  ...  5.549232  7.321264  4.439630  4.270849  6.389187  5.204595   \n",
      "1803  ...  5.537877  7.245087  4.513218  5.564480  6.326717  5.308253   \n",
      "\n",
      "         TRAF3      POLI      OPA1    NKX2-8  \n",
      "0     7.506855  7.187923  8.141370  5.397719  \n",
      "1     7.499798  7.146426  8.103407  5.415061  \n",
      "2     7.493658  7.140231  8.059044  5.411218  \n",
      "3     7.537081  7.224992  8.124222  5.373220  \n",
      "4     7.502487  7.156748  8.130588  5.387827  \n",
      "...        ...       ...       ...       ...  \n",
      "1799  7.433912  7.239027  8.312906  5.376982  \n",
      "1800  7.423804  6.959910  8.279451  5.416526  \n",
      "1801  7.359203  7.210399  8.288896  5.373969  \n",
      "1802  7.477365  7.187913  8.246703  5.394664  \n",
      "1803  7.281103  7.264024  8.165498  5.375205  \n",
      "\n",
      "[1804 rows x 12094 columns]\n"
     ]
    }
   ],
   "source": [
    "def getPatientID(sampleID):\n",
    "    return sampleID.split('-')[0] + '-' + sampleID.split('-')[1].split('_', 1)[1]\n",
    "\n",
    "dataset.insert(1, 'PatientID', dataset['SampleID'].apply(getPatientID))\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "gruppi = dataset.groupby('PatientID')\n",
    "\n",
    "def sanity_check(gruppi):\n",
    "    for group_name, group_data in gruppi:\n",
    "        if 'Control' in group_data['SampleID'].iloc[0]:\n",
    "            for e in group_data['SampleID']:\n",
    "                if not 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "        else:\n",
    "            for e in group_data['SampleID']:\n",
    "                if 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "\n",
    "sanity_check(gruppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset di train:\n",
      "(1340, 12094)\n",
      "I malati sono:  521\n",
      "I sani sono:  819\n",
      "\n",
      "Dataset di test:\n",
      "(464, 12094)\n",
      "I malati sono:  177\n",
      "I sani sono:  287\n"
     ]
    }
   ],
   "source": [
    "#n_splits number of re-shuffling & splitting iterations.\n",
    "#test_size represents the proportion of the dataset to include in the test split.\n",
    "#random_state is the seed used by the random number generator.\n",
    "splitter = GroupShuffleSplit(n_splits=2, test_size=0.25, random_state = 42)\n",
    "split = splitter.split(dataset, groups=dataset['PatientID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = dataset.iloc[train_inds].sample(frac=1, random_state=42)\n",
    "test = dataset.iloc[test_inds].sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Dataset di train:\")\n",
    "print(train.shape)\n",
    "print(\"I malati sono: \", sum(train['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(train['Label'] == 0))\n",
    "\n",
    "print(\"\\nDataset di test:\")\n",
    "print(test.shape)\n",
    "print(\"I malati sono: \", sum(test['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(test['Label'] == 0))\n",
    "\n",
    "#malati train 45.12 perc\n",
    "#malati test 42.49 perc\n",
    "#malati sul totale 44.49 perc\n",
    "\n",
    "y_train = train['Label']\n",
    "x_train = train.drop(columns=['SampleID', 'Label', 'PatientID'])\n",
    "\n",
    "y_test = test['Label']\n",
    "x_test = test.drop(columns=['SampleID', 'Label', 'PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, hyperparameters, x_train, y_train, printTrain, njobs): \n",
    "    pipeline = Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', model)])\n",
    "    gridSearch = GridSearchCV(pipeline, param_grid=hyperparameters, cv=5, return_train_score=True, refit=True, n_jobs=njobs, verbose=10, error_score='raise') if printTrain == True else GridSearchCV(pipeline, param_grid=hyperparameters, cv=5, return_train_score=False, refit=True, n_jobs=njobs, verbose=10, error_score='raise')\n",
    "    gridSearch.fit(x_train, y_train)\n",
    "    print(\"Best model:\", gridSearch.best_estimator_, gridSearch.best_params_)\n",
    "    print(\"Best score:\", np.max(gridSearch.cv_results_['mean_test_score']))\n",
    "    print(\"All scores:\", gridSearch.cv_results_['mean_test_score'])\n",
    "    return gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = trainModel(SVC(), {\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf'], \n",
    "    'classifier__probability': [True],\n",
    "    'classifier__C': [2**-5, 2**-3, 2**-1, 2**0, 2**1, 2**3, 2**7, 2**9, 2**11, 2**13, 2**15],\n",
    "    'classifier__gamma': [2**-15, 2**-13, 2**-11, 2**-9, 2**-7, 2**-5, 2**-3, 2**-1, 2**1, 2**3, 2**5, 'scale', 'auto']}, x_train, y_train, False, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier', SVC(C=128, gamma=0.0078125, probability=True))]) {'classifier__C': 128, 'classifier__gamma': 0.0078125, 'classifier__kernel': 'rbf', 'classifier__probability': True}\n",
      "Best score: 0.9783582089552239\n",
      "All scores: [0.59328358 0.61119403 0.61119403 0.59328358 0.61119403 0.61119403\n",
      " 0.59328358 0.61119403 0.61119403 0.59328358 0.70671642 0.61119403\n",
      " 0.59328358 0.88059701 0.61119403 0.59328358 0.88059701 0.61119403\n",
      " 0.59328358 0.88059701 0.61119403 0.59328358 0.88059701 0.61119403\n",
      " 0.59328358 0.88059701 0.61119403 0.59328358 0.88059701 0.61119403\n",
      " 0.59328358 0.88059701 0.61119403 0.59328358 0.87985075 0.61119403\n",
      " 0.59328358 0.61119403 0.61119403 0.60671642 0.61119403 0.61119403\n",
      " 0.60671642 0.61119403 0.61119403 0.60671642 0.61119403 0.61119403\n",
      " 0.60671642 0.87238806 0.61119403 0.60671642 0.88059701 0.64776119\n",
      " 0.60671642 0.88059701 0.61119403 0.60671642 0.88059701 0.61119403\n",
      " 0.60671642 0.88059701 0.61119403 0.60671642 0.88059701 0.61119403\n",
      " 0.60671642 0.88059701 0.61119403 0.60671642 0.88059701 0.61119403\n",
      " 0.60671642 0.88134328 0.63358209 0.60671642 0.61119403 0.61119403\n",
      " 0.60522388 0.61119403 0.61119403 0.60522388 0.61119403 0.61119403\n",
      " 0.60522388 0.61492537 0.61119403 0.60522388 0.88358209 0.70149254\n",
      " 0.60522388 0.88059701 0.91791045 0.60522388 0.88059701 0.64253731\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.85447761\n",
      " 0.60522388 0.61119403 0.61119403 0.60522388 0.61119403 0.61119403\n",
      " 0.60522388 0.61119403 0.61119403 0.60522388 0.64179104 0.61343284\n",
      " 0.60522388 0.88134328 0.84328358 0.60522388 0.88059701 0.95597015\n",
      " 0.60522388 0.88059701 0.87014925 0.60522388 0.88059701 0.61268657\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.92985075 0.60522388 0.61119403 0.61119403\n",
      " 0.60522388 0.61119403 0.61119403 0.60522388 0.61119403 0.61119403\n",
      " 0.60522388 0.70671642 0.63731343 0.60522388 0.88059701 0.9238806\n",
      " 0.60522388 0.88059701 0.96268657 0.60522388 0.88059701 0.88208955\n",
      " 0.60522388 0.88059701 0.62238806 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.95746269\n",
      " 0.60522388 0.61119403 0.61119403 0.60522388 0.61119403 0.61119403\n",
      " 0.60522388 0.61119403 0.61940299 0.60522388 0.87238806 0.83656716\n",
      " 0.60522388 0.88059701 0.95597015 0.60522388 0.88059701 0.9761194\n",
      " 0.60522388 0.88059701 0.88134328 0.60522388 0.88059701 0.62238806\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.96716418 0.60522388 0.61119403 0.6119403\n",
      " 0.60522388 0.61119403 0.66791045 0.60522388 0.70671642 0.79850746\n",
      " 0.60522388 0.88059701 0.93358209 0.60522388 0.88059701 0.96940299\n",
      " 0.60522388 0.88059701 0.97835821 0.60522388 0.88059701 0.88134328\n",
      " 0.60522388 0.88059701 0.62238806 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.9761194\n",
      " 0.60522388 0.61865672 0.74925373 0.60522388 0.61119403 0.67238806\n",
      " 0.60522388 0.87238806 0.8141791  0.60522388 0.88059701 0.93358209\n",
      " 0.60522388 0.88059701 0.96940299 0.60522388 0.88059701 0.97835821\n",
      " 0.60522388 0.88059701 0.88134328 0.60522388 0.88059701 0.62238806\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.9761194  0.60522388 0.73283582 0.77313433\n",
      " 0.60522388 0.61492537 0.68656716 0.60522388 0.88358209 0.8141791\n",
      " 0.60522388 0.88059701 0.93358209 0.60522388 0.88059701 0.96940299\n",
      " 0.60522388 0.88059701 0.97835821 0.60522388 0.88059701 0.88134328\n",
      " 0.60522388 0.88059701 0.62238806 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.9761194\n",
      " 0.60522388 0.87985075 0.77238806 0.60522388 0.70671642 0.68507463\n",
      " 0.60522388 0.88059701 0.8141791  0.60522388 0.88059701 0.93358209\n",
      " 0.60522388 0.88059701 0.96940299 0.60522388 0.88059701 0.97835821\n",
      " 0.60522388 0.88059701 0.88134328 0.60522388 0.88059701 0.62238806\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.9761194  0.60522388 0.88358209 0.77238806\n",
      " 0.60522388 0.87238806 0.68507463 0.60522388 0.88059701 0.8141791\n",
      " 0.60522388 0.88059701 0.93358209 0.60522388 0.88059701 0.96940299\n",
      " 0.60522388 0.88059701 0.97835821 0.60522388 0.88059701 0.88134328\n",
      " 0.60522388 0.88059701 0.62238806 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.61119403\n",
      " 0.60522388 0.88059701 0.61119403 0.60522388 0.88059701 0.9761194\n",
      " 0.60522388 0.88059701 0.77238806]\n"
     ]
    }
   ],
   "source": [
    "svc = joblib.load('../../Modelli/Dataset-136411/svc.pkl')\n",
    "print(\"Best model:\", svc.best_estimator_, svc.best_params_)\n",
    "print(\"Best score:\", np.max(svc.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", svc.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = trainModel(RandomForestClassifier(), {\n",
    "    'classifier__n_estimators': [i for i in range(150, 251, 25)],\n",
    "    'classifier__max_depth': [i for i in range(4, 13)]}, x_train, y_train, True, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(max_depth=12, n_estimators=225))]) {'classifier__max_depth': 12, 'classifier__n_estimators': 225}\n",
      "Best score: 0.9723880597014926\n",
      "All scores: [0.92686567 0.9261194  0.92761194 0.92835821 0.92761194 0.94552239\n",
      " 0.94328358 0.94104478 0.94328358 0.94253731 0.95746269 0.95447761\n",
      " 0.95522388 0.95746269 0.95597015 0.95895522 0.96044776 0.96567164\n",
      " 0.96268657 0.9641791  0.96567164 0.96716418 0.97089552 0.96567164\n",
      " 0.96791045 0.96567164 0.9619403  0.96641791 0.96567164 0.96343284\n",
      " 0.96641791 0.96791045 0.96716418 0.96791045 0.96567164 0.96865672\n",
      " 0.96716418 0.96791045 0.96492537 0.97089552 0.96940299 0.96791045\n",
      " 0.96865672 0.97238806 0.96641791]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       287\n",
      "           1       0.90      0.94      0.92       177\n",
      "\n",
      "    accuracy                           0.94       464\n",
      "   macro avg       0.93      0.94      0.93       464\n",
      "weighted avg       0.94      0.94      0.94       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomForest = joblib.load('../../Modelli/Dataset-136411/randomForest.pkl')\n",
    "print(\"Best model:\", randomForest.best_estimator_, randomForest.best_params_)\n",
    "print(\"Best score:\", np.max(randomForest.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", randomForest.cv_results_['mean_test_score'])\n",
    "\n",
    "y_pred = randomForest.predict(x_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNet = trainModel(LogisticRegression(), {\n",
    "    'classifier__C': [2**-7, 2**-5, 2**-3, 2**-1, 2**0, 2**1, 2**3, 2**7, 2**9, 2**11],\n",
    "    'classifier__penalty': ['elasticnet'],\n",
    "    'classifier__l1_ratio': [0, 0.0001, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "    'classifier__solver': ['saga']}, x_train, y_train, True, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=0.5, l1_ratio=1, penalty='elasticnet',\n",
      "                                    solver='saga'))]) {'classifier__C': 0.5, 'classifier__l1_ratio': 1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}\n",
      "Best score: 0.7283582089552239\n",
      "All scores: [0.62835821 0.62910448 0.61119403 0.61119403 0.61119403 0.61119403\n",
      " 0.61119403 0.62089552 0.62164179 0.64029851 0.6119403  0.61119403\n",
      " 0.61119403 0.61119403 0.60447761 0.60447761 0.66791045 0.70671642\n",
      " 0.66567164 0.63656716 0.63059701 0.60298507 0.60447761 0.62537313\n",
      " 0.65597015 0.69179104 0.71940299 0.72835821 0.60074627 0.60298507\n",
      " 0.61567164 0.62761194 0.65671642 0.67835821 0.69402985 0.60373134\n",
      " 0.60223881 0.60820896 0.61716418 0.62910448 0.64179104 0.66044776\n",
      " 0.60447761 0.60223881 0.60223881 0.60746269 0.61119403 0.61567164\n",
      " 0.61791045 0.60149254 0.60149254 0.60223881 0.60298507 0.60223881\n",
      " 0.60373134 0.60298507 0.60298507 0.60149254 0.60223881 0.60149254\n",
      " 0.60223881 0.60298507 0.60223881 0.60223881 0.60447761 0.60223881\n",
      " 0.60149254 0.60373134 0.60447761 0.60373134]\n"
     ]
    }
   ],
   "source": [
    "elasticNet = joblib.load('../../Modelli/Dataset-136411/elasticNet.pkl')\n",
    "print(\"Best model:\", elasticNet.best_estimator_, elasticNet.best_params_)\n",
    "print(\"Best score:\", np.max(elasticNet.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", elasticNet.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = trainModel(KNeighborsClassifier(), {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'] }, x_train, y_train, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier', KNeighborsClassifier(n_neighbors=3))]) {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'}\n",
      "Best score: 0.7970149253731342\n",
      "All scores: [0.79701493 0.79701493 0.78208955 0.78208955 0.7761194  0.7761194\n",
      " 0.76865672 0.76865672 0.76791045 0.76791045 0.76716418 0.76716418\n",
      " 0.76119403 0.76119403]\n"
     ]
    }
   ],
   "source": [
    "knn = joblib.load('../../Modelli/Dataset-136411/knn.pkl')\n",
    "print(\"Best model:\", knn.best_estimator_, knn.best_params_)\n",
    "print(\"Best score:\", np.max(knn.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", knn.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HistGradientBoosting = trainModel(HistGradientBoostingClassifier(), {\n",
    "    'classifier__max_depth': [3, 5, 7, 9, 11],\n",
    "    'classifier__max_iter': [100, 150, 200, 250],\n",
    "    'classifier__learning_rate': [0.1, 0.01, 0.001]}, x_train, y_train, False, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier', HistGradientBoostingClassifier(max_depth=9))]) {'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_iter': 100}\n",
      "Best score: 0.9783582089552239\n",
      "All scores: [0.97164179 0.97537313 0.97686567 0.97761194 0.97686567 0.97686567\n",
      " 0.9761194  0.97537313 0.9738806  0.9738806  0.97537313 0.97537313\n",
      " 0.97835821 0.97537313 0.97537313 0.9761194  0.97686567 0.9761194\n",
      " 0.9761194  0.97686567 0.95373134 0.96567164 0.96865672 0.97164179\n",
      " 0.95522388 0.96641791 0.97089552 0.97537313 0.95671642 0.96343284\n",
      " 0.97164179 0.9761194  0.95671642 0.96268657 0.97238806 0.97537313\n",
      " 0.95671642 0.96268657 0.97014925 0.97462687 0.61119403 0.61119403\n",
      " 0.64925373 0.85373134 0.61119403 0.61119403 0.64328358 0.89701493\n",
      " 0.61119403 0.61119403 0.64701493 0.89925373 0.61119403 0.61119403\n",
      " 0.64850746 0.89925373 0.61119403 0.61119403 0.64850746 0.89925373]\n"
     ]
    }
   ],
   "source": [
    "HistGradientBoosting = joblib.load('../../Modelli/Dataset-136411/HistGradientBoosting.pkl')\n",
    "print(\"Best model:\", HistGradientBoosting.best_estimator_, HistGradientBoosting.best_params_)\n",
    "print(\"Best score:\", np.max(HistGradientBoosting.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", HistGradientBoosting.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoosting = trainModel(GradientBoostingClassifier(), {\n",
    "    'classifier__max_depth': [3, 5, 7, 9, 11],\n",
    "    'classifier__max_iter': [100, 150, 200, 250],\n",
    "    'classifier__learning_rate': [0.1, 0.01, 0.001]}, x_train, y_train, False, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
      "                ('classifier', GradientBoostingClassifier(n_estimators=200))]) {'classifier__learning_rate': 0.1, 'classifier__loss': 'log_loss', 'classifier__max_depth': 3, 'classifier__n_estimators': 200}\n",
      "Best score: 0.9753731343283581\n",
      "All scores: [0.97164179 0.97462687 0.97537313 0.96343284 0.96268657 0.96044776\n",
      " 0.92238806 0.92537313 0.92761194 0.94104478 0.95671642 0.96119403\n",
      " 0.94029851 0.94328358 0.94402985 0.92313433 0.92238806 0.92313433\n",
      " 0.61119403 0.61119403 0.6119403  0.61119403 0.61119403 0.61268657\n",
      " 0.61119403 0.61119403 0.61119403]\n"
     ]
    }
   ],
   "source": [
    "GradientBoosting = joblib.load('../../Modelli/Dataset-136411/GradientBoosting.pkl')\n",
    "print(\"Best model:\", GradientBoosting.best_estimator_, GradientBoosting.best_params_)\n",
    "print(\"Best score:\", np.max(GradientBoosting.cv_results_['mean_test_score']))\n",
    "print(\"All scores:\", GradientBoosting.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GaussianNB())])\n",
    "print(naiveBayes.fit(x_train, y_train).score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238805970149254\n"
     ]
    }
   ],
   "source": [
    "naiveBayes = joblib.load('../../Modelli/Dataset-136411/naiveBayes.pkl')\n",
    "print(naiveBayes.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance dei vari modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Iperparametri:  {'classifier__C': 128, 'classifier__gamma': 0.0078125, 'classifier__kernel': 'rbf', 'classifier__probability': True}\n",
      "Training accuracy:  0.9783582089552239\n",
      "Test accuracy:  0.9525862068965517 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       287\n",
      "           1       0.92      0.96      0.94       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.95      0.95      0.95       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      " \n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Iperparametri:  {'classifier__max_depth': 12, 'classifier__n_estimators': 225}\n",
      "Training accuracy:  0.9723880597014926\n",
      "Test accuracy:  0.9353448275862069 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       287\n",
      "           1       0.90      0.94      0.92       177\n",
      "\n",
      "    accuracy                           0.94       464\n",
      "   macro avg       0.93      0.94      0.93       464\n",
      "weighted avg       0.94      0.94      0.94       464\n",
      " \n",
      "\n",
      "\n",
      "Elastic Net:\n",
      "Iperparametri:  {'classifier__C': 0.5, 'classifier__l1_ratio': 1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}\n",
      "Training accuracy:  0.7283582089552239\n",
      "Test accuracy:  0.7672413793103449 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83       287\n",
      "           1       0.76      0.57      0.65       177\n",
      "\n",
      "    accuracy                           0.77       464\n",
      "   macro avg       0.76      0.73      0.74       464\n",
      "weighted avg       0.77      0.77      0.76       464\n",
      " \n",
      "\n",
      "\n",
      "KNN:\n",
      "Iperparametri:  {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'}\n",
      "Training accuracy:  0.7970149253731342\n",
      "Test accuracy:  0.7521551724137931 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       287\n",
      "           1       0.78      0.49      0.60       177\n",
      "\n",
      "    accuracy                           0.75       464\n",
      "   macro avg       0.76      0.70      0.71       464\n",
      "weighted avg       0.76      0.75      0.74       464\n",
      " \n",
      "\n",
      "\n",
      "Hist Gradient Boosting:\n",
      "Iperparametri:  {'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_iter': 100}\n",
      "Training accuracy:  0.9783582089552239\n",
      "Test accuracy:  0.9504310344827587 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       287\n",
      "           1       0.91      0.97      0.94       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.94      0.95      0.95       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      " \n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Iperparametri:  {'classifier__learning_rate': 0.1, 'classifier__loss': 'log_loss', 'classifier__max_depth': 3, 'classifier__n_estimators': 200}\n",
      "Training accuracy:  0.9753731343283581\n",
      "Test accuracy:  0.9418103448275862 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       287\n",
      "           1       0.92      0.93      0.92       177\n",
      "\n",
      "    accuracy                           0.94       464\n",
      "   macro avg       0.94      0.94      0.94       464\n",
      "weighted avg       0.94      0.94      0.94       464\n",
      " \n",
      "\n",
      "\n",
      "Naive Bayes:\n",
      "Iperparametri:  Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GaussianNB())])\n",
      "Training accuracy:  0.9238805970149254\n",
      "Test accuracy:  0.9051724137931034 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       287\n",
      "           1       0.99      0.76      0.86       177\n",
      "\n",
      "    accuracy                           0.91       464\n",
      "   macro avg       0.93      0.88      0.89       464\n",
      "weighted avg       0.92      0.91      0.90       464\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prettyPrint(model, name):\n",
    "    if isinstance(model, Pipeline):\n",
    "        print(name + \":\")\n",
    "        print(\"Iperparametri: \", model)\n",
    "        print(\"Training accuracy: \", model.score(x_train, y_train))\n",
    "        print(\"Test accuracy: \", model.score(x_test, y_test), \"\\n\")\n",
    "        print(classification_report(y_test, model.predict(x_test)), \"\\n\\n\")\n",
    "    else:\n",
    "        print(name + \":\")\n",
    "        print(\"Iperparametri: \", model.best_params_)\n",
    "        print(\"Training accuracy: \", model.best_score_)\n",
    "        print(\"Test accuracy: \", model.score(x_test, y_test), \"\\n\")\n",
    "        print(classification_report(y_test, model.predict(x_test)), \"\\n\\n\")\n",
    "\n",
    "for model, name in [(svc, \"SVC\"), (randomForest, \"Random Forest\"), (elasticNet, \"Elastic Net\"), (knn, \"KNN\"), (HistGradientBoosting, \"Hist Gradient Boosting\"), (GradientBoosting, \"Gradient Boosting\"), (naiveBayes, \"Naive Bayes\")]:\n",
    "    prettyPrint(model, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
