{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from combat.pycombat import pycombat\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../Dataset/Merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione Training e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\combat\\pycombat.py:159: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.absolute(d_new-d_old)/d_old))  # maximum difference between new and old estimate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the Data\n",
      "                                         SampleID      PatientID  Label  \\\n",
      "0                        0-GSM1026056_600009.0001  0-600009.0001      1   \n",
      "1             0-GSM1026057_600009.0001-FollowUp_1  0-600009.0001      1   \n",
      "2                         0-GSM1026058_41461.0001   0-41461.0001      1   \n",
      "3                         0-GSM1026059_41462.0001   0-41462.0001      1   \n",
      "4                        0-GSM1026060_600029.0001  0-600029.0001      1   \n",
      "...                                           ...            ...    ...   \n",
      "1799  5-GSM2347715_NT142_W18D2-Control-FollowUp_1  5-NT142_W18D2      0   \n",
      "1800  5-GSM2347717_NT041_W18D2-Control-FollowUp_2  5-NT041_W18D2      0   \n",
      "1801  5-GSM2347719_NT142_W18D2-Control-FollowUp_2  5-NT142_W18D2      0   \n",
      "1802  5-GSM2347721_NT041_W18D2-Control-FollowUp_3  5-NT041_W18D2      0   \n",
      "1803  5-GSM2347723_NT142_W18D2-Control-FollowUp_3  5-NT142_W18D2      0   \n",
      "\n",
      "        STEEP1   SEC14L1     YIPF5    SLC1A5        C2      NOL6     SPRR3  \\\n",
      "0     5.140886  8.939040  7.488400  7.308738  5.041389  7.277062  4.196267   \n",
      "1     5.329654  8.963625  7.489870  7.253862  5.052384  7.265726  4.194572   \n",
      "2     5.334372  8.988408  7.494769  7.255859  5.088023  7.264864  4.238121   \n",
      "3     5.569576  8.951902  7.528364  7.242488  4.982092  7.261708  4.153170   \n",
      "4     5.400919  8.974480  7.506864  7.262843  5.105506  7.250928  4.162485   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1799  5.609098  8.824586  7.598167  6.961956  4.745473  7.147771  4.175185   \n",
      "1800  5.493972  9.086668  7.444133  7.146979  5.391719  7.108745  4.200994   \n",
      "1801  4.592469  8.675869  7.609213  6.715370  4.550844  7.096102  4.157819   \n",
      "1802  5.992676  9.085231  7.454065  7.371060  5.636887  7.157697  4.151017   \n",
      "1803  5.547987  8.728035  7.581867  6.792434  4.405267  7.090149  4.265779   \n",
      "\n",
      "      ...     PALLD     KRCC1     RAB25  CATSPERB      PAX8     KCNG1  \\\n",
      "0     ...  5.308174  7.072927  4.488145  4.631166  6.337192  5.362835   \n",
      "1     ...  5.289479  7.079105  4.536805  4.606074  6.356049  5.377468   \n",
      "2     ...  5.314215  7.115176  4.518818  4.597691  6.388240  5.391885   \n",
      "3     ...  5.269752  7.316362  4.446099  4.676782  6.334405  5.321966   \n",
      "4     ...  5.243430  7.192371  4.505834  4.569492  6.339356  5.303483   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "1799  ...  5.767658  7.442899  4.478639  5.736174  6.343809  5.550462   \n",
      "1800  ...  5.437960  7.321505  4.442908  4.189680  6.385842  5.210415   \n",
      "1801  ...  5.251095  7.349944  4.397669  5.718701  6.316099  5.223182   \n",
      "1802  ...  5.549232  7.321264  4.439630  4.270849  6.389187  5.204595   \n",
      "1803  ...  5.537877  7.245087  4.513218  5.564480  6.326717  5.308253   \n",
      "\n",
      "         TRAF3      POLI      OPA1    NKX2-8  \n",
      "0     7.506855  7.187923  8.141370  5.397719  \n",
      "1     7.499798  7.146426  8.103407  5.415061  \n",
      "2     7.493658  7.140231  8.059044  5.411218  \n",
      "3     7.537081  7.224992  8.124222  5.373220  \n",
      "4     7.502487  7.156748  8.130588  5.387827  \n",
      "...        ...       ...       ...       ...  \n",
      "1799  7.433912  7.239027  8.312906  5.376982  \n",
      "1800  7.423804  6.959910  8.279451  5.416526  \n",
      "1801  7.359203  7.210399  8.288896  5.373969  \n",
      "1802  7.477365  7.187913  8.246703  5.394664  \n",
      "1803  7.281103  7.264024  8.165498  5.375205  \n",
      "\n",
      "[1804 rows x 12094 columns]\n",
      "Dataset di train:\n",
      "(1340, 12094)\n",
      "I malati sono:  521\n",
      "I sani sono:  819\n",
      "\n",
      "Dataset di test:\n",
      "(464, 12094)\n",
      "I malati sono:  177\n",
      "I sani sono:  287\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('MergedDataset-136411.csv', index_col=0)\n",
    "\n",
    "sampleID = dataset['SampleID']\n",
    "datasetID = dataset['SampleID'].apply(lambda x: x.split('-')[0]).values\n",
    "indicator = dataset['Label']\n",
    "dataset = dataset.drop(columns=['SampleID', 'Label'])\n",
    "\n",
    "dataset = pycombat(dataset.transpose(), datasetID).transpose()\n",
    "dataset.insert(0, 'SampleID', sampleID)\n",
    "dataset.insert(1, 'Label', indicator)\n",
    "\n",
    "def getPatientID(sampleID):\n",
    "    return sampleID.split('-')[0] + '-' + sampleID.split('-')[1].split('_', 1)[1]\n",
    "\n",
    "dataset.insert(1, 'PatientID', dataset['SampleID'].apply(getPatientID))\n",
    "print(dataset)\n",
    "\n",
    "gruppi = dataset.groupby('PatientID')\n",
    "\n",
    "def sanity_check(gruppi):\n",
    "    for group_name, group_data in gruppi:\n",
    "        if 'Control' in group_data['SampleID'].iloc[0]:\n",
    "            for e in group_data['SampleID']:\n",
    "                if not 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "        else:\n",
    "            for e in group_data['SampleID']:\n",
    "                if 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "\n",
    "sanity_check(gruppi)\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=2, test_size=0.25, random_state = 42)\n",
    "split = splitter.split(dataset, groups=dataset['PatientID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = dataset.iloc[train_inds].sample(frac=1, random_state=42)\n",
    "test = dataset.iloc[test_inds].sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Dataset di train:\")\n",
    "print(train.shape)\n",
    "print(\"I malati sono: \", sum(train['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(train['Label'] == 0))\n",
    "\n",
    "print(\"\\nDataset di test:\")\n",
    "print(test.shape)\n",
    "print(\"I malati sono: \", sum(test['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(test['Label'] == 0))\n",
    "\n",
    "y_train = train['Label']\n",
    "x_train = train.drop(columns=['SampleID', 'Label', 'PatientID'])\n",
    "\n",
    "y_test = test['Label']\n",
    "x_test = test.drop(columns=['SampleID', 'Label', 'PatientID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = joblib.load('../../Modelli/DatasetReduced/svc.pkl')\n",
    "randomForest = joblib.load('../../Modelli/DatasetReduced/randomForest.pkl')\n",
    "elasticNet = joblib.load('../../Modelli/DatasetReduced/elasticNet.pkl')\n",
    "knn = joblib.load('../../Modelli/DatasetReduced/knn.pkl')\n",
    "HistgradientBoosting = joblib.load('../../Modelli/DatasetReduced/HistGradientBoosting.pkl')\n",
    "GradientBoosting = joblib.load('../../Modelli/DatasetReduced/GradientBoosting.pkl')\n",
    "naiveBayes = joblib.load('../../Modelli/DatasetReduced/naiveBayes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSvc = SVC(C=svc.best_params_['classifier__C'], kernel=svc.best_params_['classifier__kernel'], gamma=svc.best_params_['classifier__gamma'], probability=True)\n",
    "newRandomForest = RandomForestClassifier(n_estimators=randomForest.best_params_['classifier__n_estimators'], max_depth=randomForest.best_params_['classifier__max_depth'])\n",
    "newElasticNet = LogisticRegression(penalty=elasticNet.best_params_['classifier__penalty'], C=elasticNet.best_params_['classifier__C'], l1_ratio=elasticNet.best_params_['classifier__l1_ratio'], solver=elasticNet.best_params_['classifier__solver'])\n",
    "newKnn = KNeighborsClassifier(n_neighbors=knn.best_params_['classifier__n_neighbors'], weights=knn.best_params_['classifier__weights'])\n",
    "newHistGradientBoosting = HistGradientBoostingClassifier(learning_rate=HistgradientBoosting.best_params_['classifier__learning_rate'], max_iter=HistgradientBoosting.best_params_['classifier__max_iter'], max_depth=HistgradientBoosting.best_params_['classifier__max_depth'])\n",
    "newGradientBoosting = GradientBoostingClassifier(learning_rate=GradientBoosting.best_params_['classifier__learning_rate'], n_estimators=GradientBoosting.best_params_['classifier__n_estimators'], max_depth=GradientBoosting.best_params_['classifier__max_depth'])\n",
    "newNaiveBayes = GaussianNB();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleModel = VotingClassifier(estimators=[('svc', newSvc), ('randomForest', newRandomForest), ('HistGradientBoosting', newHistGradientBoosting), ('gradientBoosting', newGradientBoosting), ('naiveBayes', newNaiveBayes)], voting='hard')\n",
    "ensemble = Pipeline(steps=[('scaler', MinMaxScaler()), ('classifier', ensembleModel)])\n",
    "ensemble.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistGradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())])\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9461206896551724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       287\n",
      "           1       0.92      0.94      0.93       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.94      0.94      0.94       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble = joblib.load('../../Modelli/DatasetReduced/ensemble.pkl')\n",
    "print(\"Ensemble model:\")\n",
    "print(\"Iperparametri: \", ensemble.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensemble.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensemble.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensemble.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightSum = sum([model.best_score_ for model in [svc, randomForest, HistgradientBoosting, GradientBoosting]])\n",
    "weightSum += naiveBayes.score(x_train, y_train)\n",
    "\n",
    "weights = [model.best_score_ / weightSum for model in [svc, randomForest, HistgradientBoosting, GradientBoosting]]\n",
    "weights.append(naiveBayes.score(x_train, y_train) / weightSum)\n",
    "\n",
    "ensembleModelWeighted = VotingClassifier(estimators=[('svc', newSvc), ('randomForest', newRandomForest), ('HistgradientBoosting', newHistGradientBoosting), ('gradientBoosting', newGradientBoosting), ('naiveBayes', newNaiveBayes)],voting='soft', weights=weights, n_jobs=-1)\n",
    "ensembleWeighted = Pipeline(steps=[('scaler', MinMaxScaler()), ('classifier', ensembleModelWeighted)])\n",
    "ensembleWeighted.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weighted model:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistgradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())],\n",
      "                 n_jobs=-1, voting='soft',\n",
      "                 weights=[0.2026275115919629, 0.20139103554868626,\n",
      "                          0.2026275115919629, 0.20200927357032458,\n",
      "                          0.1913446676970634])\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9482758620689655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       287\n",
      "           1       0.93      0.93      0.93       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.95      0.95      0.95       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensembleWeighted = joblib.load('../../Modelli/Dataset-136411/ensembleWeighted.pkl')\n",
    "\n",
    "print(\"Ensemble weighted model:\")\n",
    "print(\"Iperparametri: \", ensembleWeighted.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensembleWeighted.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensembleWeighted.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensembleWeighted.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyEnsemble(x, models):\n",
    "    Y_pred_proba_ensemble = [0 for i in range(len(x))]\n",
    "    count = 0\n",
    "    for i in range(len(models)):\n",
    "        gs=models[i]\n",
    "        count+=1\n",
    "        Y_pred_proba = gs.predict_proba(x)\n",
    "        Y_pred_proba_ensemble = [Y_pred_proba_ensemble[k] + Y_pred_proba[k, 1] for k in range(len(x))]\n",
    "    Y_pred_proba_ensemble = np.array(Y_pred_proba_ensemble)\n",
    "    Y_pred_proba_ensemble = Y_pred_proba_ensemble / count\n",
    "    Y_pred_ensemble = (Y_pred_proba_ensemble > 0.5)*1\n",
    "    return Y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [svc, randomForest, HistgradientBoosting, GradientBoosting, naiveBayes]\n",
    "trainResult = applyEnsemble(x_train, models)\n",
    "testResult = applyEnsemble(x_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Manual ensemble model:\")\n",
    "print(\"Models: svc, randomForest, HistgradientBoosting, gradientBoosting, naiveBayes\")\n",
    "print(\"Training accuracy: \", sum(trainResult == y_train) / len(y_train))\n",
    "print(\"Test accuracy: \", sum(testResult == y_test) / len(y_test))\n",
    "print(classification_report(y_test, testResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Modelli/DatasetReduced/ensembleSoft.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembleSoft = VotingClassifier(estimators=[('svc', newSvc), ('randomForest', newRandomForest), ('HistGradientBoosting', newHistGradientBoosting), ('gradientBoosting', newGradientBoosting), ('naiveBayes', newNaiveBayes)], voting='soft')\n",
    "ensemble = Pipeline(steps=[('scaler', MinMaxScaler()), ('classifier', ensembleSoft)])\n",
    "ensemble.fit(x_train, y_train)\n",
    "joblib.dump(ensemble, '../../Modelli/DatasetReduced/ensembleSoft.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble soft model:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistGradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())],\n",
      "                 voting='soft')\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9461206896551724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       287\n",
      "           1       0.93      0.93      0.93       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.94      0.94      0.94       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensembleSoft = joblib.load('../../Modelli/DatasetReduced/ensembleSoft.pkl')\n",
    "\n",
    "print(\"Ensemble soft model:\")\n",
    "print(\"Iperparametri: \", ensembleSoft.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensembleSoft.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensembleSoft.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensembleSoft.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = joblib.load('../../Modelli/DatasetReduced/ensemble.pkl')\n",
    "ensembleSoft = joblib.load('../../Modelli/DatasetReduced/ensembleSoft.pkl')\n",
    "ensembleWeighted = joblib.load('../../Modelli/DatasetReduced/ensembleWeighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_title('Curva ROC DatasetReduced')\n",
    "\n",
    "ensembleSoft_disp = RocCurveDisplay.from_estimator(ensembleSoft, x_test, y_test, name=\"Ensemble Soft\", ax=ax)\n",
    "ensembleWeighted_disp = RocCurveDisplay.from_estimator(ensembleWeighted, x_test, y_test, name=\"Ensemble Weighted\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DatasetFull </h1>\n",
    "\n",
    "| Modello                     | Iperparametri                                                                                                               | Training Accuracy | Test Accuracy | Precision | Recall | F1-score | Support |\n",
    "|-----------------------------|-----------------------------------------------------------------------------------------------------------------------------|-------------------|---------------|-----------|--------|----------|---------|\n",
    "| SVC                         | {'classifier__C': 128, 'classifier__gamma': 0.0078125, 'classifier__kernel': 'rbf'}                                      | 0.9448            | 0.95          | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Random Forest               | {'classifier__max_depth': 9, 'classifier__n_estimators': 200}                                                             | 0.9347            | 0.9423        | 0.94      | 0.94   | 0.94     | 520     |\n",
    "| Elastic Net                 | {'classifier__C': 0.5, 'classifier__l1_ratio': 1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'} | 0.7062            | 0.6865        | 0.68      | 0.69   | 0.68     | 520     |\n",
    "| KNN                         | {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'}                                                          | 0.8920            | 0.8827        | 0.88      | 0.88   | 0.88     | 520     |\n",
    "| Hist Gradient Boosting      | {'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_iter': 200}                               | 0.9491            | 0.9538        | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Gradient Boosting           | Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GradientBoostingClassifier(max_depth=5, n_estimators=150))])  | 1.0               | 0.9442        | 0.94      | 0.95   | 0.94     | 520     |\n",
    "| Naive Bayes                 | Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GaussianNB())])                                               | 0.9153            | 0.9404        | 0.94      | 0.94   | 0.94     | 520     |\n",
    "| Ensemble model              | VotingClassifier(estimators=[('svc', SVC(C=128, gamma=0.0078125, probability=True)), ...                                  | 1.0               | 0.95          | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Ensemble weighted model     | VotingClassifier(estimators=[('svc', SVC(C=128, gamma=0.0078125, probability=True)), ...                                  | 1.0               | 0.9462        | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Manual ensemble model       | Models: svc, randomForest, knn, HistgradientBoosting, gradientBoosting, naiveBayes                                         | 1.0               | 0.95          | 0.95      | 0.95   | 0.95     | 520     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DatasetZeroes </h1>\n",
    "\n",
    "| Modello                     | Iperparametri                                                                                                                               | Training Accuracy | Test Accuracy | Precision | Recall | F1-score | Support |\n",
    "|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|-------------------|---------------|-----------|--------|----------|---------|\n",
    "| SVC                         | {'classifier__C': 8, 'classifier__gamma': 0.0078125, 'classifier__kernel': 'rbf', 'classifier__probability': True}                        | 0.9278            | 0.9462        | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Random Forest               | {'classifier__max_depth': 12, 'classifier__n_estimators': 225}                                                                           | 0.9353            | 0.9365        | 0.94      | 0.94   | 0.94     | 520     |\n",
    "| Elastic Net                 | {'classifier__C': 0.5, 'classifier__l1_ratio': 1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}                   | 0.6296            | 0.6404        | 0.67      | 0.63   | 0.61     | 520     |\n",
    "| KNN                         | {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'}                                                                          | 0.6692            | 0.6769        | 0.73      | 0.69   | 0.67     | 520     |\n",
    "| Hist Gradient Boosting      | {'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__max_iter': 200}                                             | 0.9510            | 0.9558        | 0.96      | 0.96   | 0.96     | 520     |\n",
    "| Gradient Boosting           | {'classifier__learning_rate': 0.1, 'classifier__loss': 'log_loss', 'classifier__max_depth': 5, 'classifier__n_estimators': 150}       | 0.9485            | 0.95          | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Naive Bayes                 | Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GaussianNB())])                                                             | 0.9184            | 0.9404        | 0.94      | 0.94   | 0.94     | 520     |\n",
    "| Ensemble model              | VotingClassifier(estimators=[('svc', SVC(C=8, gamma=0.0078125, probability=True)), ...                                                     | 0.9711            | 0.9462        | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Ensemble weighted model     | VotingClassifier(estimators=[('svc', SVC(C=8, gamma=0.0078125, probability=True)), ...                                                     | 0.9912            | 0.9481        | 0.95      | 0.95   | 0.95     | 520     |\n",
    "| Manual ensemble model       | Models: svc, randomForest, HistgradientBoosting, gradientBoosting, naiveBayes                                                            | 0.9887            | 0.9481        | 0.95      | 0.95   | 0.95     | 520     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DatasetReduced </h1>\n",
    "\n",
    "| Modello                     | Iperparametri                                                                                                                    | Training Accuracy | Test Accuracy | Precision | Recall | F1-score | Support |\n",
    "|-----------------------------|----------------------------------------------------------------------------------------------------------------------------------|-------------------|---------------|-----------|--------|----------|---------|\n",
    "| SVC                         | {'classifier__C': 128, 'classifier__gamma': 0.0078125, 'classifier__kernel': 'rbf', 'classifier__probability': True}          | 0.9784            | 0.9526        | 0.95      | 0.95   | 0.95     | 464     |\n",
    "| Random Forest               | {'classifier__max_depth': 12, 'classifier__n_estimators': 225}                                                                  | 0.9724            | 0.9353        | 0.94      | 0.94   | 0.94     | 464     |\n",
    "| Elastic Net                 | {'classifier__C': 0.5, 'classifier__l1_ratio': 1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}        | 0.7284            | 0.7672        | 0.76      | 0.73   | 0.74     | 464     |\n",
    "| KNN                         | {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'}                                                                 | 0.7970            | 0.7522        | 0.76      | 0.70   | 0.71     | 464     |\n",
    "| Hist Gradient Boosting      | {'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_iter': 100}                                    | 0.9784            | 0.9504        | 0.94      | 0.95   | 0.95     | 464     |\n",
    "| Gradient Boosting           | {'classifier__learning_rate': 0.1, 'classifier__loss': 'log_loss', 'classifier__max_depth': 3, 'classifier__n_estimators': 200} | 0.9754            | 0.9418        | 0.94      | 0.94   | 0.94     | 464     |\n",
    "| Naive Bayes                 | Pipeline(steps=[('Scaling', MinMaxScaler()), ('classifier', GaussianNB())])                                                    | 0.9239            | 0.9052        | 0.93      | 0.88   | 0.89     | 464     |\n",
    "| Ensemble model              | VotingClassifier(estimators=[('svc', SVC(C=128, gamma=0.0078125, probability=True)), ...                                          | 1.0               | 0.9461        | 0.95      | 0.94   | 0.94     | 464     |\n",
    "| Ensemble weighted model     | VotingClassifier(estimators=[('svc', SVC(C=128, gamma=0.0078125, probability=True)), ...                                          | 1.0               | 0.9483        | 0.95      | 0.95   | 0.95     | 464     |\n",
    "| Manual ensemble model       | Models: svc, randomForest, HistgradientBoosting, gradientBoosting, naiveBayes                                                   | 1.0               | 0.9461        | 0.94      | 0.94   | 0.94     | 464     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creazione modello ensemble ridotto</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleSoft = joblib.load('../../Modelli/DatasetReduced/ensembleSoft.pkl')\n",
    "rfe = joblib.load('../../ShapValues/DatasetReduced/ensembleSoft_featureSelection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistGradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())],\n",
      "                 voting='soft')\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9461206896551724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       287\n",
      "           1       0.93      0.93      0.93       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.94      0.94      0.94       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble model:\")\n",
    "print(\"Iperparametri: \", ensembleSoft.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensembleSoft.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensembleSoft.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensembleSoft.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889\n"
     ]
    }
   ],
   "source": [
    "keys_with_value = [key for key, value in rfe.items() if value > 0.98]\n",
    "sorted_keys = sorted(keys_with_value, key=lambda x: len(x), reverse=False)\n",
    "feature = sorted_keys[0]\n",
    "print(len(feature))\n",
    "\n",
    "x_train = x_train.filter(items=feature)\n",
    "x_test = x_test.filter(items=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              (&#x27;randomForest&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              (&#x27;HistGradientBoosting&#x27;,\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              (&#x27;gradientBoosting&#x27;,\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              (&#x27;randomForest&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              (&#x27;HistGradientBoosting&#x27;,\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              (&#x27;gradientBoosting&#x27;,\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
       "                             (&#x27;randomForest&#x27;,\n",
       "                              RandomForestClassifier(max_depth=12,\n",
       "                                                     n_estimators=225)),\n",
       "                             (&#x27;HistGradientBoosting&#x27;,\n",
       "                              HistGradientBoostingClassifier(max_depth=9)),\n",
       "                             (&#x27;gradientBoosting&#x27;,\n",
       "                              GradientBoostingClassifier(n_estimators=200)),\n",
       "                             (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=128, gamma=0.0078125, probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>randomForest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=12, n_estimators=225)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>HistGradientBoosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_depth=9)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gradientBoosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>naiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('classifier',\n",
       "                 VotingClassifier(estimators=[('svc',\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              ('randomForest',\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              ('HistGradientBoosting',\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              ('gradientBoosting',\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              ('naiveBayes', GaussianNB())],\n",
       "                                  voting='soft'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembleSoft.fit(x_train.filter(items=feature), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Modelli/DatasetReduced/ensembleSelected.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ensembleSoft, '../../Modelli/DatasetReduced/ensembleSelected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDX3Y</th>\n",
       "      <th>USP9Y</th>\n",
       "      <th>GIT2</th>\n",
       "      <th>PABPC1</th>\n",
       "      <th>RPS4Y1</th>\n",
       "      <th>C4BPA</th>\n",
       "      <th>HLA-DRB5</th>\n",
       "      <th>HLA-DRB1</th>\n",
       "      <th>UBR4</th>\n",
       "      <th>CRIPTO</th>\n",
       "      <th>...</th>\n",
       "      <th>ECI2</th>\n",
       "      <th>GNA15</th>\n",
       "      <th>TOMM40</th>\n",
       "      <th>RASSF4</th>\n",
       "      <th>MUTYH</th>\n",
       "      <th>MPC1</th>\n",
       "      <th>SLC2A3</th>\n",
       "      <th>EFHD1</th>\n",
       "      <th>ADISSP</th>\n",
       "      <th>FIP1L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>3.478338</td>\n",
       "      <td>3.390917</td>\n",
       "      <td>7.339206</td>\n",
       "      <td>9.011070</td>\n",
       "      <td>5.654172</td>\n",
       "      <td>5.082899</td>\n",
       "      <td>10.393213</td>\n",
       "      <td>11.849403</td>\n",
       "      <td>7.310957</td>\n",
       "      <td>3.912018</td>\n",
       "      <td>...</td>\n",
       "      <td>7.466534</td>\n",
       "      <td>7.708360</td>\n",
       "      <td>7.344711</td>\n",
       "      <td>7.230549</td>\n",
       "      <td>7.202806</td>\n",
       "      <td>8.614218</td>\n",
       "      <td>9.446660</td>\n",
       "      <td>5.750145</td>\n",
       "      <td>7.187047</td>\n",
       "      <td>7.286072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>4.758538</td>\n",
       "      <td>4.210808</td>\n",
       "      <td>7.366016</td>\n",
       "      <td>8.984915</td>\n",
       "      <td>6.311182</td>\n",
       "      <td>4.665264</td>\n",
       "      <td>10.140729</td>\n",
       "      <td>11.732016</td>\n",
       "      <td>7.295366</td>\n",
       "      <td>3.660566</td>\n",
       "      <td>...</td>\n",
       "      <td>7.785417</td>\n",
       "      <td>7.769904</td>\n",
       "      <td>7.088814</td>\n",
       "      <td>7.165359</td>\n",
       "      <td>7.002063</td>\n",
       "      <td>8.532284</td>\n",
       "      <td>10.380801</td>\n",
       "      <td>5.272603</td>\n",
       "      <td>7.351485</td>\n",
       "      <td>7.280454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>3.453247</td>\n",
       "      <td>3.494757</td>\n",
       "      <td>7.475489</td>\n",
       "      <td>9.012761</td>\n",
       "      <td>5.567539</td>\n",
       "      <td>5.056319</td>\n",
       "      <td>10.504884</td>\n",
       "      <td>11.958646</td>\n",
       "      <td>7.327974</td>\n",
       "      <td>3.896792</td>\n",
       "      <td>...</td>\n",
       "      <td>7.521516</td>\n",
       "      <td>8.054786</td>\n",
       "      <td>7.293100</td>\n",
       "      <td>7.069177</td>\n",
       "      <td>6.920216</td>\n",
       "      <td>8.657137</td>\n",
       "      <td>10.067189</td>\n",
       "      <td>5.195759</td>\n",
       "      <td>7.232021</td>\n",
       "      <td>7.388326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>7.362771</td>\n",
       "      <td>6.848075</td>\n",
       "      <td>7.529982</td>\n",
       "      <td>9.013460</td>\n",
       "      <td>9.831917</td>\n",
       "      <td>5.027814</td>\n",
       "      <td>10.475381</td>\n",
       "      <td>11.987391</td>\n",
       "      <td>7.358816</td>\n",
       "      <td>3.902383</td>\n",
       "      <td>...</td>\n",
       "      <td>7.472220</td>\n",
       "      <td>8.256245</td>\n",
       "      <td>7.002593</td>\n",
       "      <td>7.119234</td>\n",
       "      <td>6.954851</td>\n",
       "      <td>8.561730</td>\n",
       "      <td>10.485756</td>\n",
       "      <td>5.342661</td>\n",
       "      <td>7.042296</td>\n",
       "      <td>7.351733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>7.603659</td>\n",
       "      <td>6.497730</td>\n",
       "      <td>7.310257</td>\n",
       "      <td>9.014779</td>\n",
       "      <td>9.702537</td>\n",
       "      <td>5.056426</td>\n",
       "      <td>10.495722</td>\n",
       "      <td>12.057744</td>\n",
       "      <td>7.305035</td>\n",
       "      <td>3.869412</td>\n",
       "      <td>...</td>\n",
       "      <td>7.534005</td>\n",
       "      <td>8.253200</td>\n",
       "      <td>7.188369</td>\n",
       "      <td>7.291418</td>\n",
       "      <td>6.932555</td>\n",
       "      <td>8.616483</td>\n",
       "      <td>10.190805</td>\n",
       "      <td>5.447726</td>\n",
       "      <td>7.271306</td>\n",
       "      <td>7.300636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>3.261257</td>\n",
       "      <td>3.290192</td>\n",
       "      <td>7.398748</td>\n",
       "      <td>9.006167</td>\n",
       "      <td>4.538526</td>\n",
       "      <td>5.067946</td>\n",
       "      <td>9.670636</td>\n",
       "      <td>12.745330</td>\n",
       "      <td>7.300379</td>\n",
       "      <td>3.848794</td>\n",
       "      <td>...</td>\n",
       "      <td>7.321299</td>\n",
       "      <td>7.839850</td>\n",
       "      <td>7.102872</td>\n",
       "      <td>7.308786</td>\n",
       "      <td>6.846652</td>\n",
       "      <td>8.615150</td>\n",
       "      <td>10.349901</td>\n",
       "      <td>5.617417</td>\n",
       "      <td>7.104331</td>\n",
       "      <td>7.305998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>6.305659</td>\n",
       "      <td>5.738595</td>\n",
       "      <td>7.394014</td>\n",
       "      <td>9.015496</td>\n",
       "      <td>9.776575</td>\n",
       "      <td>5.159841</td>\n",
       "      <td>11.673924</td>\n",
       "      <td>12.373037</td>\n",
       "      <td>7.294957</td>\n",
       "      <td>3.915602</td>\n",
       "      <td>...</td>\n",
       "      <td>7.280989</td>\n",
       "      <td>7.733443</td>\n",
       "      <td>7.183699</td>\n",
       "      <td>7.302378</td>\n",
       "      <td>6.860211</td>\n",
       "      <td>8.505852</td>\n",
       "      <td>10.028519</td>\n",
       "      <td>5.537685</td>\n",
       "      <td>7.287175</td>\n",
       "      <td>7.312072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>3.198318</td>\n",
       "      <td>3.277098</td>\n",
       "      <td>7.367695</td>\n",
       "      <td>9.006439</td>\n",
       "      <td>4.143022</td>\n",
       "      <td>5.297084</td>\n",
       "      <td>11.876386</td>\n",
       "      <td>11.386428</td>\n",
       "      <td>7.311575</td>\n",
       "      <td>3.904505</td>\n",
       "      <td>...</td>\n",
       "      <td>7.856104</td>\n",
       "      <td>8.328427</td>\n",
       "      <td>7.339577</td>\n",
       "      <td>7.099131</td>\n",
       "      <td>7.003521</td>\n",
       "      <td>8.709914</td>\n",
       "      <td>10.311024</td>\n",
       "      <td>5.692966</td>\n",
       "      <td>7.678992</td>\n",
       "      <td>7.301525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>4.748259</td>\n",
       "      <td>4.239544</td>\n",
       "      <td>7.378229</td>\n",
       "      <td>8.993706</td>\n",
       "      <td>6.313508</td>\n",
       "      <td>5.085154</td>\n",
       "      <td>10.245305</td>\n",
       "      <td>11.887320</td>\n",
       "      <td>7.271946</td>\n",
       "      <td>4.217898</td>\n",
       "      <td>...</td>\n",
       "      <td>7.327832</td>\n",
       "      <td>8.041089</td>\n",
       "      <td>7.141118</td>\n",
       "      <td>7.177610</td>\n",
       "      <td>6.837019</td>\n",
       "      <td>8.569635</td>\n",
       "      <td>10.949717</td>\n",
       "      <td>5.414652</td>\n",
       "      <td>7.064544</td>\n",
       "      <td>7.289999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>6.297456</td>\n",
       "      <td>5.570777</td>\n",
       "      <td>7.401215</td>\n",
       "      <td>9.013907</td>\n",
       "      <td>9.782488</td>\n",
       "      <td>5.164384</td>\n",
       "      <td>11.449349</td>\n",
       "      <td>11.913440</td>\n",
       "      <td>7.290945</td>\n",
       "      <td>3.866969</td>\n",
       "      <td>...</td>\n",
       "      <td>7.502415</td>\n",
       "      <td>8.252463</td>\n",
       "      <td>7.182933</td>\n",
       "      <td>7.452458</td>\n",
       "      <td>6.873494</td>\n",
       "      <td>8.610920</td>\n",
       "      <td>10.402570</td>\n",
       "      <td>5.384240</td>\n",
       "      <td>7.302905</td>\n",
       "      <td>7.307802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows  1889 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DDX3Y     USP9Y      GIT2    PABPC1    RPS4Y1     C4BPA   HLA-DRB5  \\\n",
       "527   3.478338  3.390917  7.339206  9.011070  5.654172  5.082899  10.393213   \n",
       "1168  4.758538  4.210808  7.366016  8.984915  6.311182  4.665264  10.140729   \n",
       "478   3.453247  3.494757  7.475489  9.012761  5.567539  5.056319  10.504884   \n",
       "488   7.362771  6.848075  7.529982  9.013460  9.831917  5.027814  10.475381   \n",
       "357   7.603659  6.497730  7.310257  9.014779  9.702537  5.056426  10.495722   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "1460  3.261257  3.290192  7.398748  9.006167  4.538526  5.067946   9.670636   \n",
       "1504  6.305659  5.738595  7.394014  9.015496  9.776575  5.159841  11.673924   \n",
       "1741  3.198318  3.277098  7.367695  9.006439  4.143022  5.297084  11.876386   \n",
       "1143  4.748259  4.239544  7.378229  8.993706  6.313508  5.085154  10.245305   \n",
       "1500  6.297456  5.570777  7.401215  9.013907  9.782488  5.164384  11.449349   \n",
       "\n",
       "       HLA-DRB1      UBR4    CRIPTO  ...      ECI2     GNA15    TOMM40  \\\n",
       "527   11.849403  7.310957  3.912018  ...  7.466534  7.708360  7.344711   \n",
       "1168  11.732016  7.295366  3.660566  ...  7.785417  7.769904  7.088814   \n",
       "478   11.958646  7.327974  3.896792  ...  7.521516  8.054786  7.293100   \n",
       "488   11.987391  7.358816  3.902383  ...  7.472220  8.256245  7.002593   \n",
       "357   12.057744  7.305035  3.869412  ...  7.534005  8.253200  7.188369   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "1460  12.745330  7.300379  3.848794  ...  7.321299  7.839850  7.102872   \n",
       "1504  12.373037  7.294957  3.915602  ...  7.280989  7.733443  7.183699   \n",
       "1741  11.386428  7.311575  3.904505  ...  7.856104  8.328427  7.339577   \n",
       "1143  11.887320  7.271946  4.217898  ...  7.327832  8.041089  7.141118   \n",
       "1500  11.913440  7.290945  3.866969  ...  7.502415  8.252463  7.182933   \n",
       "\n",
       "        RASSF4     MUTYH      MPC1     SLC2A3     EFHD1    ADISSP    FIP1L1  \n",
       "527   7.230549  7.202806  8.614218   9.446660  5.750145  7.187047  7.286072  \n",
       "1168  7.165359  7.002063  8.532284  10.380801  5.272603  7.351485  7.280454  \n",
       "478   7.069177  6.920216  8.657137  10.067189  5.195759  7.232021  7.388326  \n",
       "488   7.119234  6.954851  8.561730  10.485756  5.342661  7.042296  7.351733  \n",
       "357   7.291418  6.932555  8.616483  10.190805  5.447726  7.271306  7.300636  \n",
       "...        ...       ...       ...        ...       ...       ...       ...  \n",
       "1460  7.308786  6.846652  8.615150  10.349901  5.617417  7.104331  7.305998  \n",
       "1504  7.302378  6.860211  8.505852  10.028519  5.537685  7.287175  7.312072  \n",
       "1741  7.099131  7.003521  8.709914  10.311024  5.692966  7.678992  7.301525  \n",
       "1143  7.177610  6.837019  8.569635  10.949717  5.414652  7.064544  7.289999  \n",
       "1500  7.452458  6.873494  8.610920  10.402570  5.384240  7.302905  7.307802  \n",
       "\n",
       "[1340 rows x 1889 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembleSelected = joblib.load('../../Modelli/DatasetReduced/ensembleSelected.pkl')\n",
    "x_train[ensembleSelected.feature_names_in_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model reduced:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistGradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())],\n",
      "                 voting='soft')\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9482758620689655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       287\n",
      "           1       0.93      0.94      0.93       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.94      0.95      0.95       464\n",
      "weighted avg       0.95      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble model reduced:\")\n",
    "print(\"Iperparametri: \", ensembleSelected.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensembleSelected.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensembleSelected.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensembleSelected.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    }
   ],
   "source": [
    "keys_with_value = [key for key, value in rfe.items() if value > 0.977]\n",
    "sorted_keys = sorted(keys_with_value, key=lambda x: len(x), reverse=False)\n",
    "feature = sorted_keys[0]\n",
    "print(len(feature))\n",
    "\n",
    "x_train = x_train.filter(items=feature)\n",
    "x_test = x_test.filter(items=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              (&#x27;randomForest&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              (&#x27;HistGradientBoosting&#x27;,\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              (&#x27;gradientBoosting&#x27;,\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              (&#x27;randomForest&#x27;,\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              (&#x27;HistGradientBoosting&#x27;,\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              (&#x27;gradientBoosting&#x27;,\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                                  voting=&#x27;soft&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;svc&#x27;,\n",
       "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
       "                             (&#x27;randomForest&#x27;,\n",
       "                              RandomForestClassifier(max_depth=12,\n",
       "                                                     n_estimators=225)),\n",
       "                             (&#x27;HistGradientBoosting&#x27;,\n",
       "                              HistGradientBoostingClassifier(max_depth=9)),\n",
       "                             (&#x27;gradientBoosting&#x27;,\n",
       "                              GradientBoostingClassifier(n_estimators=200)),\n",
       "                             (&#x27;naiveBayes&#x27;, GaussianNB())],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=128, gamma=0.0078125, probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>randomForest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=12, n_estimators=225)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>HistGradientBoosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_depth=9)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gradientBoosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>naiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('classifier',\n",
       "                 VotingClassifier(estimators=[('svc',\n",
       "                                               SVC(C=128, gamma=0.0078125,\n",
       "                                                   probability=True)),\n",
       "                                              ('randomForest',\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=225)),\n",
       "                                              ('HistGradientBoosting',\n",
       "                                               HistGradientBoostingClassifier(max_depth=9)),\n",
       "                                              ('gradientBoosting',\n",
       "                                               GradientBoostingClassifier(n_estimators=200)),\n",
       "                                              ('naiveBayes', GaussianNB())],\n",
       "                                  voting='soft'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembleSoft.fit(x_train.filter(items=feature), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Modelli/DatasetReduced/ensembleSelected_373.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ensembleSoft, '../../Modelli/DatasetReduced/ensembleSelected_373.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleSelected_373 = joblib.load('../../Modelli/DatasetReduced/ensembleSelected_373.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model reduced:\n",
      "Iperparametri:  VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=128, gamma=0.0078125, probability=True)),\n",
      "                             ('randomForest',\n",
      "                              RandomForestClassifier(max_depth=12,\n",
      "                                                     n_estimators=225)),\n",
      "                             ('HistGradientBoosting',\n",
      "                              HistGradientBoostingClassifier(max_depth=9)),\n",
      "                             ('gradientBoosting',\n",
      "                              GradientBoostingClassifier(n_estimators=200)),\n",
      "                             ('naiveBayes', GaussianNB())],\n",
      "                 voting='soft')\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9547413793103449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       287\n",
      "           1       0.93      0.95      0.94       177\n",
      "\n",
      "    accuracy                           0.95       464\n",
      "   macro avg       0.95      0.95      0.95       464\n",
      "weighted avg       0.96      0.95      0.95       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble model reduced:\")\n",
    "print(\"Iperparametri: \", ensembleSelected_373.named_steps['classifier'])\n",
    "print(\"Training accuracy: \", ensembleSelected_373.score(x_train, y_train))\n",
    "print(\"Test accuracy: \", ensembleSelected_373.score(x_test, y_test))\n",
    "print(classification_report(y_test, ensembleSelected_373.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
