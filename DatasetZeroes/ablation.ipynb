{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from combat.pycombat import pycombat\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../Dataset/Merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\combat\\pycombat.py:159: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.absolute(d_new-d_old)/d_old))  # maximum difference between new and old estimate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the Data\n",
      "Dataset di train:\n",
      "(1593, 12094)\n",
      "I malati sono:  695\n",
      "I sani sono:  898\n",
      "\n",
      "Dataset di test:\n",
      "(520, 12094)\n",
      "I malati sono:  245\n",
      "I sani sono:  275\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('MergedDatasetZeroes.csv', index_col=0)\n",
    "\n",
    "sampleID = dataset['SampleID']\n",
    "datasetID = dataset['SampleID'].apply(lambda x: x.split('-')[0]).values\n",
    "indicator = dataset['Label']\n",
    "dataset = dataset.drop(columns=['SampleID', 'Label'])\n",
    "\n",
    "dataset = pycombat(dataset.transpose(), datasetID).transpose()\n",
    "\n",
    "dataset.insert(0, 'SampleID', sampleID)\n",
    "dataset.insert(1, 'Label', indicator)\n",
    "\n",
    "def getPatientID(sampleID):\n",
    "    return sampleID.split('-')[0] + '-' + sampleID.split('-')[1].split('_', 1)[1]\n",
    "\n",
    "dataset.insert(1, 'PatientID', dataset['SampleID'].apply(getPatientID))\n",
    "gruppi = dataset.groupby('PatientID')\n",
    "\n",
    "def sanity_check(gruppi):\n",
    "    for group_name, group_data in gruppi:\n",
    "        if 'Control' in group_data['SampleID'].iloc[0]:\n",
    "            for e in group_data['SampleID']:\n",
    "                if not 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "        else:\n",
    "            for e in group_data['SampleID']:\n",
    "                if 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "\n",
    "sanity_check(gruppi)\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=2, test_size=0.25, random_state = 42)\n",
    "split = splitter.split(dataset, groups=dataset['PatientID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = dataset.iloc[train_inds].sample(frac=1, random_state=42)\n",
    "test = dataset.iloc[test_inds].sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Dataset di train:\")\n",
    "print(train.shape)\n",
    "print(\"I malati sono: \", sum(train['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(train['Label'] == 0))\n",
    "\n",
    "print(\"\\nDataset di test:\")\n",
    "print(test.shape)\n",
    "print(\"I malati sono: \", sum(test['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(test['Label'] == 0))\n",
    "\n",
    "y_train = train['Label']\n",
    "x_train = train.drop(columns=['SampleID', 'Label', 'PatientID'])\n",
    "\n",
    "y_test = test['Label']\n",
    "x_test = test.drop(columns=['SampleID', 'Label', 'PatientID'])\n",
    "\n",
    "ensemble = joblib.load('../../Modelli/DatasetZeroes/ensembleSoft.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScores(x_test, y_test, model):\n",
    "    scores = {col: 0 for col in x_test.columns}\n",
    "    i = 1\n",
    "    for exclude in range(x_train.shape[1]):\n",
    "        x = x_test.copy()\n",
    "        x[x.columns[exclude]] = x[x.columns[exclude]].mean()\n",
    "        scores[x.columns[exclude]] = f1_score(y_test, model.predict(x))\n",
    "        print(i)\n",
    "        i += 1\n",
    "    return scores\n",
    "\n",
    "scores = calcScores(x_test, y_test, ensemble)\n",
    "joblib.dump(scores, '../../ShapValues/DatasetZeroes/ensemble_ablationScoresPURI.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = joblib.load('../../ShapValues/DatasetZeroes/ensembleSoft_ablationScoresPURI.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = f1_score(y_test, ensemble.predict(x_test))\n",
    "new_scores = {key: original/value for key, value in scores.items()}\n",
    "# joblib.dump(new_scores, '../../ShapValues/DatasetZeroes/ensembleSoft_ablationScores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores = joblib.load('../../ShapValues/DatasetZeroes/ensembleSoft_ablationScores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le feature migliori sono:  3 {'DDX17': 1.0021938441388343, 'HLA-DRB1': 1.0019646365422397, 'HLA-DRB5': 1.0010665169800728}\n",
      "Le feature rumorose sono:  7 {'TCN1': 0.9980353634577603, 'RNF10': 0.9980353634577603, 'FRG1': 0.9980353634577603, 'FBLN2': 0.9980353634577603, 'TRMT5': 0.9980353634577603, 'TRIM21': 0.9980353634577603, 'RPS28': 0.9980353634577603}\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = dict(sorted(new_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "bestFeatures = {key: value for key, value in sorted_scores.items() if value > 1.0}\n",
    "worstFeatures = {key: value for key, value in sorted_scores.items() if value < 1.0}\n",
    "print(\"Le feature migliori sono: \", len(bestFeatures), bestFeatures)\n",
    "print(\"Le feature rumorose sono: \", len(worstFeatures), worstFeatures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
